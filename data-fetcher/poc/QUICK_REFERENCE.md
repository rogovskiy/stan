# LangGraph Scraper - Listing/Details Model

## ğŸ¯ Quick Reference

### Two Page Types

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LISTING PAGE      â”‚  â† Start here
â”‚                     â”‚
â”‚ Contains:           â”‚
â”‚ - Links to docs     â”‚
â”‚ - Links to pages    â”‚
â”‚ - Navigation        â”‚
â”‚                     â”‚
â”‚ Action:             â”‚
â”‚ Extract & queue     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚             â”‚
           â–¼             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Detail 1 â”‚  â”‚ Detail 2 â”‚
    â”‚          â”‚  â”‚          â”‚
    â”‚ Extract  â”‚  â”‚ Extract  â”‚
    â”‚ document â”‚  â”‚ document â”‚
    â”‚   data   â”‚  â”‚   data   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼ Always return
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   LISTING   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Navigation Rules

âœ… **Allowed:**
- Listing â†’ Detail
- Detail â†’ Listing (back)
- Listing â†’ Listing

âŒ **Not Allowed:**
- Detail â†’ Detail (must go through listing)

## ğŸš€ Quick Start

```bash
cd /Users/sergei/dev/stocks/data-fetcher/poc

# Activate venv
source ../venv/bin/activate

# Run scraper
python langgraph_scraper.py \
  --url https://investor.apple.com/investor-relations/default.aspx \
  --max-pages 10 \
  --headless
```

## ğŸ“Š Output Structure

```json
{
  "success": true,
  "listing_pages_visited": [
    "https://investor.apple.com/..."
  ],
  "detail_pages_visited": [
    "https://investor.apple.com/earnings/q4-2023",
    "https://investor.apple.com/earnings/q3-2023"
  ],
  "total_pages": 5,
  "total_listings": 2,
  "total_details": 3,
  "documents_found": [
    {
      "title": "Q4 2023 Earnings Release",
      "type": "earnings_release",
      "date": "2023-11-02",
      "quarter": "Q4",
      "year": 2023,
      "page_url": "https://...",
      "download_url": "https://...pdf",
      "description": "..."
    }
  ],
  "total_documents": 3
}
```

## ğŸ”„ Workflow Summary

```
1. Start at LISTING page
   â†“
2. Classify page (Gemini)
   â†“
3. Extract links to:
   - Detail pages (queue immediately)
   - Other listings (queue for later)
   â†“
4. Visit DETAIL pages one by one
   â†“
5. Extract document metadata (Gemini)
   â†“
6. Return to LISTING
   â†“
7. Repeat until:
   - Max pages reached
   - No more pages to visit
```

## ğŸ¨ Key Features

### 1. Smart Classification
Gemini AI classifies each page as either:
- **Listing**: Hub/archive/navigation page
- **Document Details**: Specific document page

### 2. Structured Extraction
From detail pages, extracts:
- Title
- Type (earnings, 10-K, presentation, etc.)
- Date
- Quarter/Year
- Download URL
- Description

### 3. Efficient Navigation
- Queue-based (breadth-first)
- No redundant visits
- Predictable flow

### 4. Rich Output
- Separate tracking of page types
- Detailed document metadata
- Clear navigation history

## ğŸ“ Example Session

```
ğŸš€ Starting LangGraph Web Scraper
   Start URL: https://investor.apple.com/...
   Max Pages: 10
   Model: Listing/Details Page Classification

ğŸ“ Navigating to: https://investor.apple.com/...
âœ… Loaded: Apple Investor Relations

ğŸ¤– Classifying page: Apple Investor Relations...
  ğŸ“Š Type: LISTING
  ğŸ¯ Confidence: 0.95
  ğŸ’¡ Reasoning: Contains links to multiple financial sections

ğŸ“‹ Processing listing page...
  âœ… Found 8 document detail links
  âœ… Found 3 listing page links

ğŸ¤” Deciding next action...
  â¡ï¸  Visiting detail page: Q4 2023 Earnings Release

ğŸ“ Navigating to: https://investor.apple.com/earnings/q4-2023...
âœ… Loaded: Q4 2023 Earnings Release

ğŸ¤– Classifying page: Q4 2023 Earnings Release...
  ğŸ“Š Type: DOCUMENT_DETAILS
  ğŸ¯ Confidence: 0.98
  ğŸ’¡ Reasoning: Specific quarterly earnings content

ğŸ“„ Processing document details page...
  âœ… Extracted: Q4 2023 Earnings Release
     Date: 2023-11-02
     Download: https://...q4-2023.pdf

ğŸ¤” Deciding next action...
  â†©ï¸  Returning from details page to listing

âœ… Scraping Complete!
   ğŸ“‹ Listing Pages: 3
   ğŸ“„ Detail Pages: 7
   ğŸ“¦ Documents Extracted: 7
```

## ğŸ”§ Customization

### Change Max Pages

```bash
python langgraph_scraper.py --url <url> --max-pages 20
```

### Use Different Model

```bash
python langgraph_scraper.py --url <url> --model gemini-1.5-pro
```

### Save to File

```bash
python langgraph_scraper.py --url <url> --output results.json
```

### Watch Browser (Debug)

```bash
# Remove --headless to see browser
python langgraph_scraper.py --url <url> --max-pages 3
```

## ğŸ“š Documentation

- `LANGGRAPH_WORKFLOW.md` - Detailed workflow diagrams
- `LISTING_DETAILS_UPDATE.md` - Complete change documentation
- `README.md` - Full feature documentation
- `QUICKSTART.md` - Getting started guide

## âœ¨ Advantages

### vs. Traditional Scrapers
- âœ… AI-powered classification
- âœ… Structured data extraction
- âœ… Adaptive to site structure
- âœ… No hardcoded rules

### vs. Previous Version
- âœ… Simpler (2 page types vs 4)
- âœ… More predictable navigation
- âœ… Better state management
- âœ… Richer document metadata

## ğŸ¯ Best Use Cases

1. **IR Website Scraping**
   - Earnings releases
   - SEC filings
   - Presentations
   - Annual reports

2. **Document Discovery**
   - Find all documents of a type
   - Extract metadata automatically
   - Track publication dates

3. **Archive Mining**
   - Historical data collection
   - Quarterly comparisons
   - Time series analysis

## âš ï¸ Important Notes

1. **Start URL**: Should be a listing page (IR hub, archive)
2. **Rate Limiting**: Add delays if scraping many pages
3. **Error Handling**: Script continues even if individual pages fail
4. **Gemini Limits**: Text truncated to 5000 chars per page

## ğŸ› Troubleshooting

### No documents found?
- Check if start URL is a listing page
- Increase max-pages
- Run without --headless to see what's happening

### Classification errors?
- Gemini might misclassify edge cases
- Check the confidence scores
- Some pages might be hybrid (use listing logic)

### Too many pages visited?
- Reduce max-pages
- Add domain filtering in process_listing_node
- Add date filtering for old documents

## ğŸ’¡ Tips

1. Start with small max-pages (3-5) for testing
2. Use --headless for production runs
3. Save output to JSON for analysis
4. Check classification confidence scores
5. Review listing vs detail counts for balance

## ğŸš¦ Status

Current version:
- âœ… Two-page classification model
- âœ… Gemini-powered classification
- âœ… Structured data extraction
- âœ… Queue-based navigation
- âœ… Separate page tracking
- âœ… Rich console output

686 lines of code, fully documented and tested!

